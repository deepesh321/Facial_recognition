{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "facial_recognition.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepesh321/Facial_recognition/blob/master/facial_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbtGVnZpuLcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten,BatchNormalization\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.activations import relu,tanh\n",
        "\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2puzlf4uUOr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "56f4fcf0-0501-43ae-8784-98e839a490d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBrWD05auLc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anchor=[]\n",
        "pos_neg=[]\n",
        "y_values=[0]*226\n",
        "count=0\n",
        "BASE_DIR = '/content/drive/My Drive/facial_recog'\n",
        "for i in range(113):\n",
        "    #for i in range(int(565/113)):\n",
        "    ind1=0\n",
        "    ind2=0\n",
        "    while ind1==ind2:\n",
        "        ind1 = np.random.randint(10)\n",
        "        ind2 = np.random.randint(10)\n",
        "    img1 = image.load_img(BASE_DIR + '/male/' + 's'+ str(i) + '/' + str(ind1 + 1) + '.jpg',target_size=(112,112))\n",
        "    img2 = image.load_img(BASE_DIR+'/male/' +'s'+ str(i) + '/' + str(ind2 + 1) + '.jpg',target_size=(112,112))\n",
        "    img1 = image.img_to_array(img1)\n",
        "    img2 = image.img_to_array(img2)\n",
        "    img1 = np.expand_dims(img1, axis=0)\n",
        "    img2 = np.expand_dims(img2, axis=0)\n",
        "    anchor.append(img1)\n",
        "    pos_neg.append(img2)\n",
        "    y_values[count]=1\n",
        "    count=count+1\n",
        "\n",
        "for i in range(113):\n",
        "    ind1=0\n",
        "    while ind1==i:\n",
        "        ind1 = np.random.randint(113)\n",
        "    a=np.random.randint(20)\n",
        "    img1 = image.load_img(BASE_DIR + '/male/' + 's'+ str(i) + '/' + str(a + 1) + '.jpg',target_size=(112,112))\n",
        "    img2 = image.load_img(BASE_DIR+'/male/' +'s' + str(ind1) + '/' + str(a + 1) + '.jpg',target_size=(112,112))\n",
        "    img1 = image.img_to_array(img1)\n",
        "    img2 = image.img_to_array(img2)\n",
        "    img1 = np.expand_dims(img1, axis=0)\n",
        "    img2 = np.expand_dims(img2, axis=0)\n",
        "    anchor.append(img1)\n",
        "    pos_neg.append(img2)\n",
        "    y_values[count]=0\n",
        "    count=count+1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfcGOVofuLdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bd32588-c096-44d5-92f0-3064cbbee59a"
      },
      "source": [
        "anchor=np.array(anchor)\n",
        "pos_neg=np.array(pos_neg)\n",
        "anchor = np.rollaxis(anchor, 1, 0)\n",
        "anchor = anchor[0]\n",
        "pos_neg= np.rollaxis(pos_neg, 1, 0)\n",
        "pos_neg = pos_neg[0]\n",
        "y_values=np.array(y_values)\n",
        "y_values=y_values.reshape(y_values.shape[0],1)\n",
        "print(anchor.shape,pos_neg.shape,y_values.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(226, 112, 112, 3) (226, 112, 112, 3) (226, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCKCWIiguLdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    #input_image=Input(shape=(224,224,3))\n",
        "    model=Sequential()\n",
        "    model.add(VGG16(weights=None,include_top=True,input_shape=(112,112,3)))\n",
        "    model.layers[-1].activation = tanh\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128))\n",
        "    #out = Dense(128)(model.layers[-1].output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2PSMstNuLdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_loss(vects):\n",
        "    anchor,positive=vects\n",
        "    print(anchor.shape,positive.shape)\n",
        "    loss = tf.reduce_sum((anchor - positive)**2, axis=-1)\n",
        "    print(loss)\n",
        "    print(loss.shape)    \n",
        "    return loss\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9lHc1GMYfAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxWumBlbuLdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_shape=(112,112,3)\n",
        "def get_model():\n",
        "    anchor_input=Input(shape=image_shape)\n",
        "    pos_neg_input=Input(shape=image_shape)\n",
        "    my_model=build_model()\n",
        "\n",
        "    pos_neg_encoding=my_model(pos_neg_input)\n",
        "    anchor_encoding=my_model(anchor_input)\n",
        "    distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([anchor_encoding,pos_neg_encoding])\n",
        "    # distance=Activation('sigmoid')\n",
        "    return Model(inputs=[anchor_input,pos_neg_input],outputs=distance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ2EvUpSuLda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "7b0c5191-e261-4dc6-d66c-6ca1cae8f540"
      },
      "source": [
        "fr_model=get_model()\n",
        "fr_model.compile(loss=contrastive_loss, optimizer='adam', metrics=['mae'])\n",
        "fr_model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           [(None, 112, 112, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           [(None, 112, 112, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_7 (Sequential)       (None, 128)          54599592    input_22[0][0]                   \n",
            "                                                                 input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 1)            0           sequential_7[2][0]               \n",
            "                                                                 sequential_7[1][0]               \n",
            "==================================================================================================\n",
            "Total params: 54,599,592\n",
            "Trainable params: 54,599,592\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOdYg4-guLdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "39e98a0d-52c5-4eb1-8601-6855c33c36de"
      },
      "source": [
        "fr_model.fit([anchor/255.0,pos_neg/255.0],y_values,batch_size=64,epochs=10)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 226 samples\n",
            "Epoch 1/10\n",
            "226/226 [==============================] - 17s 77ms/sample - loss: 0.4879 - mean_absolute_error: 0.5000\n",
            "Epoch 2/10\n",
            "226/226 [==============================] - 17s 74ms/sample - loss: 0.4875 - mean_absolute_error: 0.5001\n",
            "Epoch 3/10\n",
            "226/226 [==============================] - 17s 75ms/sample - loss: 0.4874 - mean_absolute_error: 0.5000\n",
            "Epoch 4/10\n",
            "226/226 [==============================] - 17s 74ms/sample - loss: 0.4874 - mean_absolute_error: 0.5000\n",
            "Epoch 5/10\n",
            "226/226 [==============================] - 17s 74ms/sample - loss: 0.4871 - mean_absolute_error: 0.4999\n",
            "Epoch 6/10\n",
            "226/226 [==============================] - 16s 73ms/sample - loss: nan - mean_absolute_error: nan\n",
            "Epoch 7/10\n",
            " 64/226 [=======>......................] - ETA: 11s - loss: nan - mean_absolute_error: nan"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-25658df8bf65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_neg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}